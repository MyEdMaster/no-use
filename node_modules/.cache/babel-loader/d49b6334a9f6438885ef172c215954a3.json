{"ast":null,"code":"import _slicedToArray from \"C:\\\\Users\\\\yuwei\\\\Desktop\\\\Front_End\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/esm/slicedToArray\";\nimport { memo, useRef, useEffect, useState } from 'react';\nimport PropTypes from 'prop-types';\nvar propTypes = {\n  children: PropTypes.func.isRequired,\n  onEnd: PropTypes.func,\n  onResult: PropTypes.func\n};\nvar defaultProps = {\n  onEnd: function onEnd() {},\n  onResult: function onResult() {}\n};\nwindow.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\nexport var SpeechRekognition = function SpeechRekognition(props) {\n  var recognition = useRef(null);\n\n  var _useState = useState(false),\n      _useState2 = _slicedToArray(_useState, 2),\n      listening = _useState2[0],\n      setListening = _useState2[1];\n\n  var supported = !!window.SpeechRecognition;\n  var children = props.children,\n      onEnd = props.onEnd,\n      onResult = props.onResult;\n\n  var processResult = function processResult(event) {\n    var transcript = Array.from(event.results).map(function (result) {\n      return result[0];\n    }).map(function (result) {\n      return result.transcript;\n    }).join('');\n    onResult(transcript);\n  };\n\n  var listen = function listen() {\n    var args = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    if (listening) return;\n    var _args$lang = args.lang,\n        lang = _args$lang === void 0 ? '' : _args$lang,\n        _args$interimResults = args.interimResults,\n        interimResults = _args$interimResults === void 0 ? true : _args$interimResults;\n    setListening(true);\n    recognition.current.lang = lang;\n    recognition.current.interimResults = interimResults;\n    recognition.current.onresult = processResult; // SpeechRecognition stops automatically after inactivity\n    // We want it to keep going until we tell it to stop\n\n    recognition.current.onend = function () {\n      return recognition.current.start();\n    };\n\n    recognition.current.start();\n  };\n\n  var stop = function stop() {\n    if (!listening) return;\n    setListening(false);\n\n    recognition.current.onend = function () {};\n\n    recognition.current.stop();\n    onEnd();\n  };\n\n  useEffect(function () {\n    if (!supported) return;\n    recognition.current = new window.SpeechRecognition();\n  }, []);\n  return children({\n    listen: listen,\n    listening: listening,\n    stop: stop,\n    supported: supported\n  });\n};\nSpeechRekognition.propTypes = propTypes;\nSpeechRekognition.defaultProps = defaultProps;\nexport default memo(SpeechRekognition);","map":{"version":3,"sources":["C:\\Users\\yuwei\\Desktop\\Front_End\\src\\page\\Speak\\SpeechRecognition.js"],"names":["memo","useRef","useEffect","useState","PropTypes","propTypes","children","func","isRequired","onEnd","onResult","defaultProps","window","SpeechRecognition","webkitSpeechRecognition","SpeechRekognition","props","recognition","listening","setListening","supported","processResult","event","transcript","Array","from","results","map","result","join","listen","args","lang","interimResults","current","onresult","onend","start","stop"],"mappings":";AAAA,SACEA,IADF,EAEEC,MAFF,EAGEC,SAHF,EAIEC,QAJF,QAKO,OALP;AAMA,OAAOC,SAAP,MAAsB,YAAtB;AAEA,IAAMC,SAAS,GAAG;AAChBC,EAAAA,QAAQ,EAAEF,SAAS,CAACG,IAAV,CAAeC,UADT;AAEhBC,EAAAA,KAAK,EAAEL,SAAS,CAACG,IAFD;AAGhBG,EAAAA,QAAQ,EAAEN,SAAS,CAACG;AAHJ,CAAlB;AAMA,IAAMI,YAAY,GAAG;AACnBF,EAAAA,KAAK,EAAE,iBAAM,CAAE,CADI;AAEnBC,EAAAA,QAAQ,EAAE,oBAAM,CAAE;AAFC,CAArB;AAKAE,MAAM,CAACC,iBAAP,GAA2BD,MAAM,CAACC,iBAAP,IAA4BD,MAAM,CAACE,uBAA9D;AAEA,OAAO,IAAMC,iBAAiB,GAAG,SAApBA,iBAAoB,CAACC,KAAD,EAAW;AAC1C,MAAMC,WAAW,GAAGhB,MAAM,CAAC,IAAD,CAA1B;;AAD0C,kBAERE,QAAQ,CAAC,KAAD,CAFA;AAAA;AAAA,MAEnCe,SAFmC;AAAA,MAExBC,YAFwB;;AAG1C,MAAMC,SAAS,GAAG,CAAC,CAACR,MAAM,CAACC,iBAA3B;AAH0C,MAKxCP,QALwC,GAQtCU,KARsC,CAKxCV,QALwC;AAAA,MAMxCG,KANwC,GAQtCO,KARsC,CAMxCP,KANwC;AAAA,MAOxCC,QAPwC,GAQtCM,KARsC,CAOxCN,QAPwC;;AAU1C,MAAMW,aAAa,GAAG,SAAhBA,aAAgB,CAACC,KAAD,EAAW;AAC/B,QAAMC,UAAU,GAAGC,KAAK,CAACC,IAAN,CAAWH,KAAK,CAACI,OAAjB,EAChBC,GADgB,CACZ,UAAAC,MAAM;AAAA,aAAIA,MAAM,CAAC,CAAD,CAAV;AAAA,KADM,EAEhBD,GAFgB,CAEZ,UAAAC,MAAM;AAAA,aAAIA,MAAM,CAACL,UAAX;AAAA,KAFM,EAGhBM,IAHgB,CAGX,EAHW,CAAnB;AAKAnB,IAAAA,QAAQ,CAACa,UAAD,CAAR;AACD,GAPD;;AASA,MAAMO,MAAM,GAAG,SAATA,MAAS,GAAe;AAAA,QAAdC,IAAc,uEAAP,EAAO;AAC5B,QAAIb,SAAJ,EAAe;AADa,qBAKxBa,IALwB,CAG1BC,IAH0B;AAAA,QAG1BA,IAH0B,2BAGnB,EAHmB;AAAA,+BAKxBD,IALwB,CAI1BE,cAJ0B;AAAA,QAI1BA,cAJ0B,qCAIT,IAJS;AAM5Bd,IAAAA,YAAY,CAAC,IAAD,CAAZ;AACAF,IAAAA,WAAW,CAACiB,OAAZ,CAAoBF,IAApB,GAA2BA,IAA3B;AACAf,IAAAA,WAAW,CAACiB,OAAZ,CAAoBD,cAApB,GAAqCA,cAArC;AACAhB,IAAAA,WAAW,CAACiB,OAAZ,CAAoBC,QAApB,GAA+Bd,aAA/B,CAT4B,CAU5B;AACA;;AACAJ,IAAAA,WAAW,CAACiB,OAAZ,CAAoBE,KAApB,GAA4B;AAAA,aAAMnB,WAAW,CAACiB,OAAZ,CAAoBG,KAApB,EAAN;AAAA,KAA5B;;AACApB,IAAAA,WAAW,CAACiB,OAAZ,CAAoBG,KAApB;AACD,GAdD;;AAgBA,MAAMC,IAAI,GAAG,SAAPA,IAAO,GAAM;AACjB,QAAI,CAACpB,SAAL,EAAgB;AAChBC,IAAAA,YAAY,CAAC,KAAD,CAAZ;;AACAF,IAAAA,WAAW,CAACiB,OAAZ,CAAoBE,KAApB,GAA4B,YAAM,CAAE,CAApC;;AACAnB,IAAAA,WAAW,CAACiB,OAAZ,CAAoBI,IAApB;AACA7B,IAAAA,KAAK;AACN,GAND;;AAQAP,EAAAA,SAAS,CAAC,YAAM;AACd,QAAI,CAACkB,SAAL,EAAgB;AAChBH,IAAAA,WAAW,CAACiB,OAAZ,GAAsB,IAAItB,MAAM,CAACC,iBAAX,EAAtB;AACD,GAHQ,EAGN,EAHM,CAAT;AAKA,SAAOP,QAAQ,CAAC;AACdwB,IAAAA,MAAM,EAANA,MADc;AAEdZ,IAAAA,SAAS,EAATA,SAFc;AAGdoB,IAAAA,IAAI,EAAJA,IAHc;AAIdlB,IAAAA,SAAS,EAATA;AAJc,GAAD,CAAf;AAMD,CAtDM;AAwDPL,iBAAiB,CAACV,SAAlB,GAA8BA,SAA9B;AACAU,iBAAiB,CAACJ,YAAlB,GAAiCA,YAAjC;AAEA,eAAeX,IAAI,CAACe,iBAAD,CAAnB","sourcesContent":["import {\n  memo,\n  useRef,\n  useEffect,\n  useState\n} from 'react';\nimport PropTypes from 'prop-types';\n\nconst propTypes = {\n  children: PropTypes.func.isRequired,\n  onEnd: PropTypes.func,\n  onResult: PropTypes.func\n};\n\nconst defaultProps = {\n  onEnd: () => {},\n  onResult: () => {}\n};\n\nwindow.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n\nexport const SpeechRekognition = (props) => {\n  const recognition = useRef(null);\n  const [listening, setListening] = useState(false);\n  const supported = !!window.SpeechRecognition;\n  const {\n    children,\n    onEnd,\n    onResult\n  } = props;\n\n  const processResult = (event) => {\n    const transcript = Array.from(event.results)\n      .map(result => result[0])\n      .map(result => result.transcript)\n      .join('');\n\n    onResult(transcript);\n  };\n\n  const listen = (args = {}) => {\n    if (listening) return;\n    const {\n      lang = '',\n      interimResults = true\n    } = args;\n    setListening(true);\n    recognition.current.lang = lang;\n    recognition.current.interimResults = interimResults;\n    recognition.current.onresult = processResult;\n    // SpeechRecognition stops automatically after inactivity\n    // We want it to keep going until we tell it to stop\n    recognition.current.onend = () => recognition.current.start();\n    recognition.current.start();\n  };\n\n  const stop = () => {\n    if (!listening) return;\n    setListening(false);\n    recognition.current.onend = () => {};\n    recognition.current.stop();\n    onEnd();\n  };\n\n  useEffect(() => {\n    if (!supported) return;\n    recognition.current = new window.SpeechRecognition();\n  }, []);\n\n  return children({\n    listen,\n    listening,\n    stop,\n    supported\n  });\n};\n\nSpeechRekognition.propTypes = propTypes;\nSpeechRekognition.defaultProps = defaultProps;\n\nexport default memo(SpeechRekognition);\n"]},"metadata":{},"sourceType":"module"}