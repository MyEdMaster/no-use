{"ast":null,"code":"import _slicedToArray from \"/Users/vivian/Desktop/Front_End/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\nimport { useRef, useEffect, useState } from 'react';\nwindow.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n\nvar useSpeechRecognition = function useSpeechRecognition() {\n  var props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n  var _props$onEnd = props.onEnd,\n      onEnd = _props$onEnd === void 0 ? function () {} : _props$onEnd,\n      _props$onResult = props.onResult,\n      onResult = _props$onResult === void 0 ? function () {} : _props$onResult;\n  var recognition = useRef(null);\n\n  var _useState = useState(false),\n      _useState2 = _slicedToArray(_useState, 2),\n      listening = _useState2[0],\n      setListening = _useState2[1];\n\n  var supported = !!window.SpeechRecognition;\n\n  var processResult = function processResult(event) {\n    var transcript = Array.from(event.results).map(function (result) {\n      return result[0];\n    }).map(function (result) {\n      return result.transcript;\n    }).join('');\n    onResult(transcript);\n  };\n\n  var listen = function listen() {\n    var args = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    if (listening) return;\n    var _args$lang = args.lang,\n        lang = _args$lang === void 0 ? '' : _args$lang,\n        _args$interimResults = args.interimResults,\n        interimResults = _args$interimResults === void 0 ? true : _args$interimResults;\n    setListening(true);\n    recognition.current.lang = lang;\n    recognition.current.interimResults = interimResults;\n    recognition.current.onresult = processResult; // SpeechRecognition stops automatically after inactivity\n    // We want it to keep going until we tell it to stop\n\n    recognition.current.onend = function () {\n      return recognition.current.start();\n    };\n\n    recognition.current.start();\n  };\n\n  var stop = function stop() {\n    if (!listening) return;\n\n    recognition.current.onresult = function () {};\n\n    recognition.current.onend = function () {};\n\n    setListening(false);\n    recognition.current.stop();\n    onEnd();\n  };\n\n  useEffect(function () {\n    if (!supported) return;\n    recognition.current = new window.SpeechRecognition();\n  }, []);\n  return {\n    listen: listen,\n    listening: listening,\n    stop: stop,\n    supported: supported\n  };\n};\n\nexport default useSpeechRecognition;","map":{"version":3,"sources":["/Users/vivian/Desktop/Front_End/src/page/Speak/useSpeechRecognition.js"],"names":["useRef","useEffect","useState","window","SpeechRecognition","webkitSpeechRecognition","useSpeechRecognition","props","onEnd","onResult","recognition","listening","setListening","supported","processResult","event","transcript","Array","from","results","map","result","join","listen","args","lang","interimResults","current","onresult","onend","start","stop"],"mappings":";AAAA,SACEA,MADF,EAEEC,SAFF,EAGEC,QAHF,QAIO,OAJP;AAMAC,MAAM,CAACC,iBAAP,GAA2BD,MAAM,CAACC,iBAAP,IAA4BD,MAAM,CAACE,uBAA9D;;AAEA,IAAMC,oBAAoB,GAAG,SAAvBA,oBAAuB,GAAgB;AAAA,MAAfC,KAAe,uEAAP,EAAO;AAAA,qBAIvCA,KAJuC,CAEzCC,KAFyC;AAAA,MAEzCA,KAFyC,6BAEjC,YAAM,CAAE,CAFyB;AAAA,wBAIvCD,KAJuC,CAGzCE,QAHyC;AAAA,MAGzCA,QAHyC,gCAG9B,YAAM,CAAE,CAHsB;AAK3C,MAAMC,WAAW,GAAGV,MAAM,CAAC,IAAD,CAA1B;;AAL2C,kBAMTE,QAAQ,CAAC,KAAD,CANC;AAAA;AAAA,MAMpCS,SANoC;AAAA,MAMzBC,YANyB;;AAO3C,MAAMC,SAAS,GAAG,CAAC,CAACV,MAAM,CAACC,iBAA3B;;AAEA,MAAMU,aAAa,GAAG,SAAhBA,aAAgB,CAACC,KAAD,EAAW;AAC/B,QAAMC,UAAU,GAAGC,KAAK,CAACC,IAAN,CAAWH,KAAK,CAACI,OAAjB,EAChBC,GADgB,CACZ,UAAAC,MAAM;AAAA,aAAIA,MAAM,CAAC,CAAD,CAAV;AAAA,KADM,EAEhBD,GAFgB,CAEZ,UAAAC,MAAM;AAAA,aAAIA,MAAM,CAACL,UAAX;AAAA,KAFM,EAGhBM,IAHgB,CAGX,EAHW,CAAnB;AAKAb,IAAAA,QAAQ,CAACO,UAAD,CAAR;AACD,GAPD;;AASA,MAAMO,MAAM,GAAG,SAATA,MAAS,GAAe;AAAA,QAAdC,IAAc,uEAAP,EAAO;AAC5B,QAAIb,SAAJ,EAAe;AADa,qBAEiBa,IAFjB,CAEpBC,IAFoB;AAAA,QAEpBA,IAFoB,2BAEb,EAFa;AAAA,+BAEiBD,IAFjB,CAETE,cAFS;AAAA,QAETA,cAFS,qCAEQ,IAFR;AAG5Bd,IAAAA,YAAY,CAAC,IAAD,CAAZ;AACAF,IAAAA,WAAW,CAACiB,OAAZ,CAAoBF,IAApB,GAA2BA,IAA3B;AACAf,IAAAA,WAAW,CAACiB,OAAZ,CAAoBD,cAApB,GAAqCA,cAArC;AACAhB,IAAAA,WAAW,CAACiB,OAAZ,CAAoBC,QAApB,GAA+Bd,aAA/B,CAN4B,CAO5B;AACA;;AACAJ,IAAAA,WAAW,CAACiB,OAAZ,CAAoBE,KAApB,GAA4B;AAAA,aAAMnB,WAAW,CAACiB,OAAZ,CAAoBG,KAApB,EAAN;AAAA,KAA5B;;AACApB,IAAAA,WAAW,CAACiB,OAAZ,CAAoBG,KAApB;AACD,GAXD;;AAaA,MAAMC,IAAI,GAAG,SAAPA,IAAO,GAAM;AACjB,QAAI,CAACpB,SAAL,EAAgB;;AAChBD,IAAAA,WAAW,CAACiB,OAAZ,CAAoBC,QAApB,GAA+B,YAAM,CAAE,CAAvC;;AACAlB,IAAAA,WAAW,CAACiB,OAAZ,CAAoBE,KAApB,GAA4B,YAAM,CAAE,CAApC;;AACAjB,IAAAA,YAAY,CAAC,KAAD,CAAZ;AACAF,IAAAA,WAAW,CAACiB,OAAZ,CAAoBI,IAApB;AACAvB,IAAAA,KAAK;AACN,GAPD;;AASAP,EAAAA,SAAS,CAAC,YAAM;AACd,QAAI,CAACY,SAAL,EAAgB;AAChBH,IAAAA,WAAW,CAACiB,OAAZ,GAAsB,IAAIxB,MAAM,CAACC,iBAAX,EAAtB;AACD,GAHQ,EAGN,EAHM,CAAT;AAKA,SAAO;AACLmB,IAAAA,MAAM,EAANA,MADK;AAELZ,IAAAA,SAAS,EAATA,SAFK;AAGLoB,IAAAA,IAAI,EAAJA,IAHK;AAILlB,IAAAA,SAAS,EAATA;AAJK,GAAP;AAMD,CAnDD;;AAqDA,eAAeP,oBAAf","sourcesContent":["import {\n  useRef,\n  useEffect,\n  useState\n} from 'react';\n\nwindow.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n\nconst useSpeechRecognition = (props = {}) => {\n  const {\n    onEnd = () => {},\n    onResult = () => {}\n  } = props;\n  const recognition = useRef(null);\n  const [listening, setListening] = useState(false);\n  const supported = !!window.SpeechRecognition;\n\n  const processResult = (event) => {\n    const transcript = Array.from(event.results)\n      .map(result => result[0])\n      .map(result => result.transcript)\n      .join('');\n\n    onResult(transcript);\n  };\n\n  const listen = (args = {}) => {\n    if (listening) return;\n    const { lang = '', interimResults = true } = args;\n    setListening(true);\n    recognition.current.lang = lang;\n    recognition.current.interimResults = interimResults;\n    recognition.current.onresult = processResult;\n    // SpeechRecognition stops automatically after inactivity\n    // We want it to keep going until we tell it to stop\n    recognition.current.onend = () => recognition.current.start();\n    recognition.current.start();\n  };\n\n  const stop = () => {\n    if (!listening) return;\n    recognition.current.onresult = () => {};\n    recognition.current.onend = () => {};\n    setListening(false);\n    recognition.current.stop();\n    onEnd();\n  };\n\n  useEffect(() => {\n    if (!supported) return;\n    recognition.current = new window.SpeechRecognition();\n  }, []);\n\n  return {\n    listen,\n    listening,\n    stop,\n    supported\n  };\n};\n\nexport default useSpeechRecognition;\n"]},"metadata":{},"sourceType":"module"}